{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\navne\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\navne\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "c:\\Users\\navne\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "c:\\Users\\navne\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from geopy import distance\n",
    "import geopandas\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import metrics\n",
    "from geopy.distance import distance\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(row):\n",
    "    point1 = (row['lat'], row['long'])\n",
    "    point2 = (row['merch_lat'], row['merch_long'])\n",
    "    dist= distance(point1, point2).km\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_file):\n",
    "    model = tf.keras.models.load_model('FinalModel')\n",
    "    df = pd.read_csv(test_file)\n",
    "    df.drop(columns={\"Unnamed: 0\"}, inplace=True)\n",
    "    df['dist'] = df.apply(calculate_distance, axis=1)\n",
    "    df['dob'] = pd.to_datetime(df['dob'], format='%Y-%m-%d')\n",
    "    now = datetime.datetime.now()\n",
    "    df['age'] = df['dob'].apply(lambda x: relativedelta(now, x).years)\n",
    "    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df['hour'] = df['trans_date_trans_time'].dt.hour\n",
    "    df['day'] = df['trans_date_trans_time'].dt.day\n",
    "    df['weekday'] = df['trans_date_trans_time'].dt.weekday\n",
    "    df['month'] = df['trans_date_trans_time'].dt.month\n",
    "    df['year'] = df['trans_date_trans_time'].dt.year\n",
    "    eps = 0.001 # 0 => 0.1Â¢\n",
    "    df['amt'] = np.log(df.pop('amt')+eps) \n",
    "    df = df.drop(columns =['trans_date_trans_time', 'dob', 'lat', 'long', 'merch_lat', 'merch_long',\n",
    "                       'merchant', 'first', 'last', 'street', 'job','trans_num','unix_time','zip','city_pop','state'])\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    test_labels = np.array(df.pop('is_fraud'))\n",
    "    test_features = np.array(df)\n",
    "    scale = StandardScaler()\n",
    "    test_features = scale.fit_transform(test_features)\n",
    "    model.summary()\n",
    "    model.evaluate(test_features, test_labels)\n",
    "    y_pred = model.predict(test_features)\n",
    "    # Convert probabilities to binary labels\n",
    "    y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "    labels = ['non-fraud', 'fraud']\n",
    "    cm = confusion_matrix(test_labels, y_pred_binary)\n",
    "    sns.heatmap(cm, annot=True,fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "    print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "    print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "    print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "    print('Total Fraudulent Transactions: ', np.sum(cm[1]))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict('your_file')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have dropped unnamed column which was removed by you\n",
    "i am not sure if your testing file would have that column or not \n",
    "please comment/uncomment if u have already removed the column-unnamed in testing file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
